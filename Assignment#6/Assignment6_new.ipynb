{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from numpy import asarray as arr\n",
    "from numpy import atleast_2d as twod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "#To shuffle data\n",
    "def shuffleData(X, Y=None):\n",
    "    \"\"\"\n",
    "    Shuffle (randomly reorder) data in X and Y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : MxN numpy array: N feature values for each of M data points\n",
    "    Y : Mx1 numpy array (optional): target values associated with each data point\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X,Y  :  (tuple of) numpy arrays of shuffled features and targets\n",
    "            only returns X (not a tuple) if Y is not present or None\n",
    "    \n",
    "    Ex:\n",
    "    X2    = shuffleData(X)   : shuffles the rows of the data matrix X\n",
    "    X2,Y2 = shuffleData(X,Y) : shuffles rows of X,Y, preserving correspondence\n",
    "    \"\"\"\n",
    "    nx,dx = twod(X).shape\n",
    "    Y = arr(Y).flatten()\n",
    "    ny = len(Y)\n",
    "\n",
    "    pi = np.random.permutation(nx)\n",
    "    X = X[pi,:]\n",
    "\n",
    "    if ny > 0:\n",
    "        assert ny == nx, 'shuffleData: X and Y must have the same length'\n",
    "        Y = Y[pi] if Y.ndim <= 1 else Y[pi,:]\n",
    "        return X,Y\n",
    "\n",
    "    return X\n",
    "\n",
    "#No of seconds considered for window size\n",
    "no_of_sec = 10;\n",
    "\n",
    "#finds Mean of data given\n",
    "def findMean(data, window_size = no_of_sec*50, stride =25):\n",
    "    return ([np.mean(data[i:i+window_size]) for i in range(0,len(data),stride) if i+window_size<=len(data)])\n",
    "\n",
    "#finds Median of data given\n",
    "def findMedian(data, window_size = no_of_sec*50, stride =25):\n",
    "    return ([np.median(data[i:i+window_size]) for i in range(0,len(data),stride) if i+window_size<=len(data)])\n",
    "\n",
    "#finds Standard Deviation of data given\n",
    "def findStd(data, window_size = no_of_sec*50, stride =25):\n",
    "    return ([np.std(data[i:i+window_size]) for i in range(0,len(data),stride) if i+window_size<=len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read data from CSV datafile\n",
    "dataset = pd.read_excel(\"data.xlsx\", nrows=43000, indexcols=[0-19]) \n",
    "array_data_original = np.array(dataset)\n",
    "\n",
    "array_data = array_data_original[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Values of activity 1 (Sitting)\n",
    "x_1 = array_data[:,2];\n",
    "y_1 = array_data[:,3];\n",
    "z_1 = array_data[:,4];\n",
    "\n",
    "#Values of activity 2 (Sleeping)\n",
    "x_2 = array_data[:,7];\n",
    "y_2 = array_data[:,8];\n",
    "z_2 = array_data[:,9];\n",
    "\n",
    "#Values of activity 3 (Standing)\n",
    "x_3 = array_data[:,12];\n",
    "y_3 = array_data[:,13];\n",
    "z_3 = array_data[:,14];\n",
    "\n",
    "#Values of activity 4 (Walking)\n",
    "x_4 = array_data[:,17];\n",
    "y_4 = array_data[:,18];\n",
    "z_4 = array_data[:,19];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding mean along each axis; appending results for all activities in a single column\n",
    "x_mean = findMean(x_1) + findMean(x_2) + findMean(x_3) + findMean(x_4)\n",
    "y_mean = findMean(y_1) + findMean(y_2) + findMean(y_3) + findMean(y_4)\n",
    "z_mean = findMean(z_1) + findMean(z_2) + findMean(z_3) + findMean(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding median along each axis; appending results for all activities in a single column\n",
    "x_median = findMedian(x_1) + findMedian(x_2) + findMedian(x_3) + findMedian(x_4)\n",
    "y_median = findMedian(y_1) + findMedian(y_2) + findMedian(y_3) + findMedian(y_4)\n",
    "z_median = findMedian(z_1) + findMedian(z_2) + findMedian(z_3) + findMedian(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding standard deviation along each axis; appending results for all activities in a single column\n",
    "x_std = findStd(x_1) + findStd(x_2) + findStd(x_3) + findStd(x_4)\n",
    "y_std = findStd(y_1) + findStd(y_2) + findStd(y_3) + findStd(y_4)\n",
    "z_std = findStd(z_1) + findStd(z_2) + findStd(z_3) + findStd(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preparing data for training the model\n",
    "data = pd.DataFrame(data={'x_mean':x_mean, 'y_mean':y_mean, 'z_mean':z_mean,\n",
    "                              'x_med':x_median, 'y_med': y_median,'z_med':z_median,\n",
    "                               'x_std': x_std, 'y_std':y_std, 'z_std':z_std})\n",
    "#Filling null data\n",
    "data = data.fillna(method='ffill')\n",
    "data_X = np.array(data)\n",
    "#Preparing the classes column for training\n",
    "no_of_repeats = len(x_mean)/4;    #number of feature rows extracted for each activity\n",
    "data_Y = np.repeat(1,no_of_repeats).tolist() + np.repeat(2,no_of_repeats).tolist() + np.repeat(3,no_of_repeats).tolist()+ np.repeat(4,no_of_repeats).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffling the data so the rows pertaining to each data are distributed in training and test data equally (on an average)\n",
    "train_X, train_Y = shuffleData(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sitting data is test data\n",
    "test_data = array_data_original[30000:43000]\n",
    "x_test = test_data[:,2];\n",
    "y_test = test_data[:,3];\n",
    "z_test = test_data[:,4];\n",
    "\n",
    "x_mean_test = findMean(x_test);\n",
    "y_mean_test = findMean(y_test);\n",
    "z_mean_test = findMean(z_test);\n",
    "\n",
    "x_median_test = findMedian(x_test);\n",
    "y_median_test = findMedian(y_test);\n",
    "z_median_test = findMedian(z_test);\n",
    "\n",
    "x_std_test = findStd(x_test);\n",
    "y_std_test = findStd(y_test);\n",
    "z_std_test = findStd(z_test);\n",
    "\n",
    "#Preparing data for training the model\n",
    "test_data = pd.DataFrame(data={'x_mean':x_mean_test, 'y_mean':y_mean_test, 'z_mean':z_mean_test,\n",
    "                              'x_med':x_median_test, 'y_med': y_median_test,'z_med':z_median_test,\n",
    "                               'x_std': x_std_test, 'y_std':y_std_test, 'z_std':z_std_test})\n",
    "test_data = test_data.fillna(method='ffill')\n",
    "test_X = np.array(test_data)\n",
    "#Preparing the classes column for training\n",
    "no_of_repeats = len(x_mean_test);    #number of feature rows extracted for each activity\n",
    "test_Y = np.repeat(1,no_of_repeats).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train a model and predict results\n",
    "def perform_model(clf, test_X = test_X, test_Y = test_Y):\n",
    "    clf.fit(train_X, train_Y)\n",
    "    #Predicting class for test and training data\n",
    "    pred_Y=clf.predict(test_X)\n",
    "    pred_Y_train = clf.predict(train_X)\n",
    "\n",
    "    errTrain=0\n",
    "    for j in range(0,len(train_Y)):\n",
    "        if train_Y[j]!=pred_Y_train[j]: #predicted!=actual\n",
    "            errTrain+=1\n",
    "    print \"Error rate for training data: \", 100*errTrain/len(train_Y)\n",
    "    \n",
    "    errTest=0\n",
    "    for j in range(0,len(test_Y)):\n",
    "        if test_Y[j]!=pred_Y[j]: #predicted!=actual\n",
    "            errTest+=1\n",
    "    print \"Error rate for test data: \", 100*errTest/len(test_Y)\n",
    "\n",
    "    print \"Score: \", clf.score(test_X,test_Y);\n",
    "    print \"Accuracy score: \", accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree results:\n",
      "Error rate for training data:  0\n",
      "Error rate for test data:  7\n",
      "Score:  0.920159680639\n",
      "Accuracy score:  0.920159680639\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "print \"\\nDecision Tree results:\"\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "perform_model(clf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
