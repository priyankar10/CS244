{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from numpy import asarray as arr\n",
    "from numpy import atleast_2d as twod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "#To shuffle data\n",
    "def shuffleData(X, Y=None):\n",
    "    \"\"\"\n",
    "    Shuffle (randomly reorder) data in X and Y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : MxN numpy array: N feature values for each of M data points\n",
    "    Y : Mx1 numpy array (optional): target values associated with each data point\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X,Y  :  (tuple of) numpy arrays of shuffled features and targets\n",
    "            only returns X (not a tuple) if Y is not present or None\n",
    "    \n",
    "    Ex:\n",
    "    X2    = shuffleData(X)   : shuffles the rows of the data matrix X\n",
    "    X2,Y2 = shuffleData(X,Y) : shuffles rows of X,Y, preserving correspondence\n",
    "    \"\"\"\n",
    "    nx,dx = twod(X).shape\n",
    "    Y = arr(Y).flatten()\n",
    "    ny = len(Y)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    pi = np.random.permutation(nx)\n",
    "    X = X[pi,:]\n",
    "\n",
    "    if ny > 0:\n",
    "        assert ny == nx, 'shuffleData: X and Y must have the same length'\n",
    "        Y = Y[pi] if Y.ndim <= 1 else Y[pi,:]\n",
    "        return X,Y\n",
    "\n",
    "    return X\n",
    "\n",
    "#No of seconds considered for window size\n",
    "no_of_sec = 10;\n",
    "\n",
    "#finds Mean of data given\n",
    "def findMean(data, window_size = no_of_sec*50, stride =25):\n",
    "    return ([np.mean(data[i:i+window_size]) for i in range(0,len(data),stride) if i+window_size<=len(data)])\n",
    "\n",
    "#finds Median of data given\n",
    "def findMedian(data, window_size = no_of_sec*50, stride =25):\n",
    "    return ([np.median(data[i:i+window_size]) for i in range(0,len(data),stride) if i+window_size<=len(data)])\n",
    "\n",
    "#finds Standard Deviation of data given\n",
    "def findStd(data, window_size = no_of_sec*50, stride =25):\n",
    "    return ([np.std(data[i:i+window_size]) for i in range(0,len(data),stride) if i+window_size<=len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read data from CSV datafile\n",
    "dataset = pd.read_excel(\"data.xlsx\", nrows=35000, indexcols=[0-19]) \n",
    "array_data = np.array(dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Values of activity 1 (Sitting)\n",
    "x_1 = array_data[:,2];\n",
    "y_1 = array_data[:,3];\n",
    "z_1 = array_data[:,4];\n",
    "\n",
    "#Values of activity 2 (Sleeping)\n",
    "x_2 = array_data[:,7];\n",
    "y_2 = array_data[:,8];\n",
    "z_2 = array_data[:,9];\n",
    "\n",
    "#Values of activity 3 (Standing)\n",
    "x_3 = array_data[:,12];\n",
    "y_3 = array_data[:,13];\n",
    "z_3 = array_data[:,14];\n",
    "\n",
    "#Values of activity 4 (Walking)\n",
    "x_4 = array_data[:,17];\n",
    "y_4 = array_data[:,18];\n",
    "z_4 = array_data[:,19];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding mean along each axis; appending results for all activities in a single column\n",
    "x_mean = findMean(x_1) + findMean(x_2) + findMean(x_3) + findMean(x_4)\n",
    "y_mean = findMean(y_1) + findMean(y_2) + findMean(y_3) + findMean(y_4)\n",
    "z_mean = findMean(z_1) + findMean(z_2) + findMean(z_3) + findMean(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding median along each axis; appending results for all activities in a single column\n",
    "x_median = findMedian(x_1) + findMedian(x_2) + findMedian(x_3) + findMedian(x_4)\n",
    "y_median = findMedian(y_1) + findMedian(y_2) + findMedian(y_3) + findMedian(y_4)\n",
    "z_median = findMedian(z_1) + findMedian(z_2) + findMedian(z_3) + findMedian(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding standard deviation along each axis; appending results for all activities in a single column\n",
    "x_std = findStd(x_1) + findStd(x_2) + findStd(x_3) + findStd(x_4)\n",
    "y_std = findStd(y_1) + findStd(y_2) + findStd(y_3) + findStd(y_4)\n",
    "z_std = findStd(z_1) + findStd(z_2) + findStd(z_3) + findStd(z_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preparing data for training the model\n",
    "data = pd.DataFrame(data={'x_mean':x_mean, 'y_mean':y_mean, 'z_mean':z_mean,\n",
    "                              'x_med':x_median, 'y_med': y_median,'z_med':z_median,\n",
    "                               'x_std': x_std, 'y_std':y_std, 'z_std':z_std})\n",
    "#To remove any null values\n",
    "data = data.fillna(method='ffill')\n",
    "data_X = np.array(data)\n",
    "#Preparing the classes column for training\n",
    "no_of_repeats = len(x_mean)/4;    #number of feature rows extracted for each activity\n",
    "data_Y = np.repeat(1,no_of_repeats).tolist() + np.repeat(2,no_of_repeats).tolist() + np.repeat(3,no_of_repeats).tolist()+ np.repeat(4,no_of_repeats).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffling the data so the rows pertaining to each data are distributed in training and test data equally (on an average)\n",
    "data_X, data_Y = shuffleData(data_X, data_Y)\n",
    "\n",
    "ind = int(np.round(0.8*len(data_X)))\n",
    "#Splitting training data as the first 80% of data\n",
    "train_X = data_X[:ind]\n",
    "train_Y = data_Y[:ind]\n",
    "\n",
    "#Splitting test data as the last 20% of data\n",
    "test_X = data_X[ind:]\n",
    "test_Y = data_Y[ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train a model and predict results\n",
    "def perform_model(clf, test_X = test_X, test_Y = test_Y):\n",
    "    clf.fit(train_X, train_Y)\n",
    "    #Predicting class for test and training data\n",
    "    pred_Y=clf.predict(test_X)\n",
    "    pred_Y_train = clf.predict(train_X)\n",
    "\n",
    "    errTrain=0\n",
    "    for j in range(0,len(train_Y)):\n",
    "        if train_Y[j]!=pred_Y_train[j]: #predicted!=actual\n",
    "            errTrain+=1\n",
    "    print \"Error rate for training data: \", 100*errTrain/len(train_Y)\n",
    "    \n",
    "    errTest=0\n",
    "    for j in range(0,len(test_Y)):\n",
    "        if test_Y[j]!=pred_Y[j]: #predicted!=actual\n",
    "            errTest+=1\n",
    "    print \"Error rate for training data: \", 100*errTest/len(test_Y)\n",
    "\n",
    "    print \"Score: \", clf.score(test_X,test_Y);\n",
    "    print \"Accuracy score: \", accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier results:\n",
      "Error rate for training data:  23\n",
      "Error rate for training data:  24\n",
      "Score:  0.759298245614\n",
      "Accuracy score:  0.759298245614\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "print \"SVM Classifier results:\"\n",
    "clf = svm.SVC(kernel = 'rbf')\n",
    "perform_model(clf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree results:\n",
      "Error rate for training data:  21\n",
      "Error rate for training data:  22\n",
      "Score:  0.774736842105\n",
      "Accuracy score:  0.774736842105\n",
      "\n",
      "KNN Classifier results:\n",
      "Error rate for training data:  16\n",
      "Error rate for training data:  27\n",
      "Score:  0.724912280702\n",
      "Accuracy score:  0.724912280702\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "print \"\\nDecision Tree results:\"\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "perform_model(clf);\n",
    "\n",
    "#KNN Classifier\n",
    "print \"\\nKNN Classifier results:\"\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "perform_model(clf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
